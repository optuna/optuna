name: examples

on:
  schedule:
    - cron: '0 15 * * *'

jobs:
  examples:

    # TODO (crcrpar): Run on 3.9.
    # ref: https://github.com/optuna/optuna/issues/2034
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.6, 3.7, 3.8]

    if: github.repository == 'optuna/optuna'
    steps:
    - uses: actions/checkout@v2
    - name: setup-python${{ matrix.python-version }}
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}
    - name: Setup cache
      uses: actions/cache@v2
      env:
        cache-name: daily-example
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-${{ matrix.python-version }}-${{ env.cache-name }}-${{ hashFiles('**/setup.py') }}-v1
        restore-keys: |
          ${{ runner.os }}-${{ matrix.python-version }}-${{ env.cache-name }}-${{ hashFiles('**/setup.py') }}
    - name: Install (apt)
      run: |
        sudo apt-get update
        sudo apt-get -y install openmpi-bin libopenmpi-dev libopenblas-dev
    - name: Install (Python)
      run: |
        python -m pip install --upgrade pip
        pip install --progress-bar off -U setuptools
        python setup.py sdist

        # Install minimal dependencies and confirm that `import optuna` is successful.
        pip install --progress-bar off $(ls dist/*.tar.gz)
        python -c 'import optuna'

        # Install all dependencies needed for examples.
        pip install --progress-bar off $(ls dist/*.tar.gz)[example] -f https://download.pytorch.org/whl/torch_stable.html

        # TODO (crcrpar): Allow fastaiv2 example once https://forums.fast.ai/t/ganlearner-error-no-implementation-found-on-types-that-implement-invisibletensor/83451/7 gets resolved.
    - name: Run examples
      run: |
        if [ ${{ matrix.python-version }} = 3.6 ]; then
          IGNORES='chainermn_.*|fastai*|pytorch_distributed_.*|rapids_.*|botorch_.*|pytorch/pytorch_checkpoint*|allennlp*'
        elif [ ${{ matrix.python-version }} = 3.8 ]; then
          IGNORES='chainermn_.*|dask_ml_.*|keras_.*|pytorch_distributed_.*|tensorboard_.*|tensorflow_.*|tfkeras_.*|fastai*|rapids_.*|pytorch/pytorch_checkpoint*|allennlp*'
        else
          IGNORES='chainermn_.*|fastai*|pytorch_distributed_.*|rapids_.*|pytorch/pytorch_checkpoint*|allennlp*'
        fi

        for file in `find examples -name '*.py' -not -name '*_distributed.py' | grep -vE "$IGNORES"`
        do
          echo $file
          python $file > /dev/null
          if grep -e '\-\-pruning' $file > /dev/null; then
            echo $file --pruning
            python $file --pruning > /dev/null
          fi
        done
      env:
        OMP_NUM_THREADS: 1
    - name: Run examples (AllenNLP)
      run: |
        pip uninstall torch torchvision torchaudio -y
        pip install --use-deprecated=legacy-resolver --progress-bar off allennlp

        IGNORES=''

        for file in `find examples -name 'allennlp*.py' -not -name '*_distributed.py' | grep -vE "$IGNORES"`
        do
          echo $file
          python $file > /dev/null
          if grep -e '\-\-pruning' $file > /dev/null; then
            echo $file --pruning
            python $file --pruning > /dev/null
          fi
        done
      env:
        OMP_NUM_THREADS: 1
    - name: Run Jupyter notebook examples
      run: |
        for file in `find examples -name '*.ipynb'`
        do
          echo $file
          pytest --nbval-lax $file > /dev/null
        done
      env:
        OMP_NUM_THREADS: 1
    - name: Run multi-node examples
      run: |
        STORAGE_URL=sqlite:///example.db
        for file in `find examples -name 'chainermn_*.py'`
        do
          echo $file
          STUDY_NAME=`optuna create-study --storage $STORAGE_URL`
          mpirun -n 2 -- python $file $STUDY_NAME $STORAGE_URL > /dev/null
        done
        mpirun -n 2 -- python examples/pytorch/pytorch_distributed_simple.py
      env:
        OMP_NUM_THREADS: 1
    - name: Run Hydra examples
      run: |
        for file in `find examples/hydra -name '*.py'`
        do
          echo $file
          python $file --multirun > /dev/null
        done
      env:
        OMP_NUM_THREADS: 1
    - name: Run PyTorch checkpoint example
      run: |
        # Unset errexit temporarily since timeout returns exit code 124.
        set +e
        timeout 20 python examples/pytorch/pytorch_checkpoint.py > /dev/null
        set -e
        python examples/pytorch/pytorch_checkpoint.py > /dev/null
      env:
        OMP_NUM_THREADS: 1
